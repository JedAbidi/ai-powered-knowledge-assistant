# ğŸ§  AI Knowledge Extractor

An AI-powered assistant that lets users upload documents and ask questions â€” receiving accurate answers grounded in those documents using Retrieval-Augmented Generation (RAG).

---

## ğŸš€ Features

- ğŸ“„ Upload documents (PDF, TXT, DOCX)
- ğŸ’¬ Ask questions based on uploaded content
- ğŸ§  See answer confidence scores + source previews
- ğŸ“š Chat history tracking and retrieval
- ğŸ—‘ï¸ Delete documents (and remove their embeddings)
- ğŸ“Š Analytics Dashboard:
  - Number of uploads
  - Most asked questions
  - Model usage over time
  - Most referenced documents

---

## ğŸ§± Tech Stack

### ğŸ–¥ Frontend
- [Next.js](https://nextjs.org/) (App Router)
- [Tailwind CSS](https://tailwindcss.com/)
- [shadcn/ui](https://ui.shadcn.com/), `axios`, `Recharts`

### âš™ï¸ Backend
- [FastAPI](https://fastapi.tiangolo.com/)
- [Chroma](https://www.trychroma.com/) for vector storage
- [LangChain](https://www.langchain.com/) for RAG pipeline
- [Hugging Face Embeddings](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
- [SQLite](https://www.sqlite.org/) (can be replaced with Supabase/PostgreSQL)

---

## ğŸ“ Project Structure

ai-knowledge-extarctor/
â”œâ”€â”€ backend/ # FastAPI backend + RAG logic
â”œâ”€â”€ frontend/ # Next.js + Tailwind UI
â””â”€â”€ README.md

---

## âš™ï¸ Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate (Windows)
pip install -r requirements.txt
uvicorn main:app --reload


Create a .env file inside backend/:
OPENAI_API_KEY=your-openai-api-key



ğŸ’» Frontend Setup :
cd frontend
npm install
npm run dev
Create a .env.local in frontend/:
NEXT_PUBLIC_API_URL=http://localhost:8000




